{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892a615a",
   "metadata": {
    "papermill": {
     "duration": 0.035322,
     "end_time": "2024-08-15T17:32:50.378443",
     "exception": false,
     "start_time": "2024-08-15T17:32:50.343121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "This project focuses on implementing and evaluating an offline reinforcement learning (RL) algorithm using the Hopper environment from the MuJoCo suite Gym MuJoCo documentation, which is part of the D4RL library. The Implicit Q-Learning (IQL) algorithm has been implemen ted in PyTorch and tested on the Hopper environment. This project also includes logging and experiment tracking using Weights & Biases (wandb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b40ad4",
   "metadata": {
    "papermill": {
     "duration": 0.032727,
     "end_time": "2024-08-15T17:32:50.444610",
     "exception": false,
     "start_time": "2024-08-15T17:32:50.411883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install Mujuco Physics engine on the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e48556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:32:50.555082Z",
     "iopub.status.busy": "2024-08-15T17:32:50.534143Z",
     "iopub.status.idle": "2024-08-15T17:35:09.709921Z",
     "shell.execute_reply": "2024-08-15T17:35:09.710433Z",
     "shell.execute_reply.started": "2024-08-15T16:03:12.160488Z"
    },
    "papermill": {
     "duration": 139.232859,
     "end_time": "2024-08-15T17:35:09.710756",
     "exception": false,
     "start_time": "2024-08-15T17:32:50.477897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://packages.cloud.google.com/apt cloud-sdk InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\r\n",
      "W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\r\n",
      "E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease' is no longer signed.\r\n",
      "W: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://packages.cloud.google.com/apt gcsfuse-focal InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\r\n",
      "W: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://packages.cloud.google.com/apt google-fast-socket InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\r\n",
      "Extracting templates from packages: 100%\r\n",
      "(Reading database ... 102169 files and directories currently installed.)\r\n",
      "Preparing to unpack .../00-libx11-6_2%3a1.6.9-2ubuntu1.6_amd64.deb ...\r\n",
      "Unpacking libx11-6:amd64 (2:1.6.9-2ubuntu1.6) over (2:1.6.9-2ubuntu1.2) ...\r\n",
      "Preparing to unpack .../01-libgl1-mesa-dri_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libgl1-mesa-dri:amd64 (21.2.6-0ubuntu0.1~20.04.2) over (21.0.3-0ubuntu0.3~20.04.4) ...\r\n",
      "Preparing to unpack .../02-libglx-mesa0_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libglx-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) over (21.0.3-0ubuntu0.3~20.04.4) ...\r\n",
      "Preparing to unpack .../03-libglapi-mesa_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libglapi-mesa:amd64 (21.2.6-0ubuntu0.1~20.04.2) over (21.0.3-0ubuntu0.3~20.04.4) ...\r\n",
      "Preparing to unpack .../04-libgl1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgl1:amd64 (1.3.2-1~ubuntu0.20.04.2) over (1.3.2-1~ubuntu0.20.04.1) ...\r\n",
      "Preparing to unpack .../05-libglx0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libglx0:amd64 (1.3.2-1~ubuntu0.20.04.2) over (1.3.2-1~ubuntu0.20.04.1) ...\r\n",
      "Preparing to unpack .../06-libglvnd0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libglvnd0:amd64 (1.3.2-1~ubuntu0.20.04.2) over (1.3.2-1~ubuntu0.20.04.1) ...\r\n",
      "Selecting previously unselected package libwayland-server0:amd64.\r\n",
      "Preparing to unpack .../07-libwayland-server0_1.18.0-1ubuntu0.1_amd64.deb ...\r\n",
      "Unpacking libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\r\n",
      "Selecting previously unselected package libgbm1:amd64.\r\n",
      "Preparing to unpack .../08-libgbm1_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libegl-mesa0:amd64.\r\n",
      "Preparing to unpack .../09-libegl-mesa0_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libegl-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libegl1:amd64.\r\n",
      "Preparing to unpack .../10-libegl1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libegl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package xorg-sgml-doctools.\r\n",
      "Preparing to unpack .../11-xorg-sgml-doctools_1%3a1.11-1_all.deb ...\r\n",
      "Unpacking xorg-sgml-doctools (1:1.11-1) ...\r\n",
      "Selecting previously unselected package x11proto-dev.\r\n",
      "Preparing to unpack .../12-x11proto-dev_2019.2-1ubuntu1_all.deb ...\r\n",
      "Unpacking x11proto-dev (2019.2-1ubuntu1) ...\r\n",
      "Selecting previously unselected package x11proto-core-dev.\r\n",
      "Preparing to unpack .../13-x11proto-core-dev_2019.2-1ubuntu1_all.deb ...\r\n",
      "Unpacking x11proto-core-dev (2019.2-1ubuntu1) ...\r\n",
      "Selecting previously unselected package libxau-dev:amd64.\r\n",
      "Preparing to unpack .../14-libxau-dev_1%3a1.0.9-0ubuntu1_amd64.deb ...\r\n",
      "Unpacking libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\r\n",
      "Selecting previously unselected package libxdmcp-dev:amd64.\r\n",
      "Preparing to unpack .../15-libxdmcp-dev_1%3a1.1.3-0ubuntu1_amd64.deb ...\r\n",
      "Unpacking libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\r\n",
      "Selecting previously unselected package xtrans-dev.\r\n",
      "Preparing to unpack .../16-xtrans-dev_1.4.0-1_all.deb ...\r\n",
      "Unpacking xtrans-dev (1.4.0-1) ...\r\n",
      "Selecting previously unselected package libpthread-stubs0-dev:amd64.\r\n",
      "Preparing to unpack .../17-libpthread-stubs0-dev_0.4-1_amd64.deb ...\r\n",
      "Unpacking libpthread-stubs0-dev:amd64 (0.4-1) ...\r\n",
      "Selecting previously unselected package libxcb1-dev:amd64.\r\n",
      "Preparing to unpack .../18-libxcb1-dev_1.14-2_amd64.deb ...\r\n",
      "Unpacking libxcb1-dev:amd64 (1.14-2) ...\r\n",
      "Selecting previously unselected package libx11-dev:amd64.\r\n",
      "Preparing to unpack .../19-libx11-dev_2%3a1.6.9-2ubuntu1.6_amd64.deb ...\r\n",
      "Unpacking libx11-dev:amd64 (2:1.6.9-2ubuntu1.6) ...\r\n",
      "Selecting previously unselected package libglx-dev:amd64.\r\n",
      "Preparing to unpack .../20-libglx-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libglx-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgl-dev:amd64.\r\n",
      "Preparing to unpack .../21-libgl-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libegl-dev:amd64.\r\n",
      "Preparing to unpack .../22-libegl-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libegl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Preparing to unpack .../23-libgl1-mesa-glx_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) over (21.0.3-0ubuntu0.3~20.04.4) ...\r\n",
      "Selecting previously unselected package libgles1:amd64.\r\n",
      "Preparing to unpack .../24-libgles1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgles1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgles2:amd64.\r\n",
      "Preparing to unpack .../25-libgles2_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgles2:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgles-dev:amd64.\r\n",
      "Preparing to unpack .../26-libgles-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libgles-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libopengl0:amd64.\r\n",
      "Preparing to unpack .../27-libopengl0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libopengl0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libopengl-dev:amd64.\r\n",
      "Preparing to unpack .../28-libopengl-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libopengl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libglvnd-dev:amd64.\r\n",
      "Preparing to unpack .../29-libglvnd-dev_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\r\n",
      "Unpacking libglvnd-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Selecting previously unselected package libgl1-mesa-dev:amd64.\r\n",
      "Preparing to unpack .../30-libgl1-mesa-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libgl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libglew2.1:amd64.\r\n",
      "Preparing to unpack .../31-libglew2.1_2.1.0-4_amd64.deb ...\r\n",
      "Unpacking libglew2.1:amd64 (2.1.0-4) ...\r\n",
      "Selecting previously unselected package libglu1-mesa:amd64.\r\n",
      "Preparing to unpack .../32-libglu1-mesa_9.0.1-1build1_amd64.deb ...\r\n",
      "Unpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\r\n",
      "Selecting previously unselected package libglu1-mesa-dev:amd64.\r\n",
      "Preparing to unpack .../33-libglu1-mesa-dev_9.0.1-1build1_amd64.deb ...\r\n",
      "Unpacking libglu1-mesa-dev:amd64 (9.0.1-1build1) ...\r\n",
      "Selecting previously unselected package libglew-dev:amd64.\r\n",
      "Preparing to unpack .../34-libglew-dev_2.1.0-4_amd64.deb ...\r\n",
      "Unpacking libglew-dev:amd64 (2.1.0-4) ...\r\n",
      "Selecting previously unselected package libglfw3:amd64.\r\n",
      "Preparing to unpack .../35-libglfw3_3.3.2-1_amd64.deb ...\r\n",
      "Unpacking libglfw3:amd64 (3.3.2-1) ...\r\n",
      "Selecting previously unselected package patchelf.\r\n",
      "Preparing to unpack .../36-patchelf_0.10-2build1_amd64.deb ...\r\n",
      "Unpacking patchelf (0.10-2build1) ...\r\n",
      "Selecting previously unselected package libosmesa6:amd64.\r\n",
      "Preparing to unpack .../37-libosmesa6_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Selecting previously unselected package libosmesa6-dev:amd64.\r\n",
      "Preparing to unpack .../38-libosmesa6-dev_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\r\n",
      "Unpacking libosmesa6-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\r\n",
      "Setting up libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libglvnd0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libpthread-stubs0-dev:amd64 (0.4-1) ...\r\n",
      "Setting up libopengl0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up xtrans-dev (1.4.0-1) ...\r\n",
      "Setting up libgles2:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libgles1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglapi-mesa:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libx11-6:amd64 (2:1.6.9-2ubuntu1.6) ...\r\n",
      "Setting up xorg-sgml-doctools (1:1.11-1) ...\r\n",
      "Setting up libopengl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up patchelf (0.10-2build1) ...\r\n",
      "Setting up libosmesa6:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up x11proto-dev (2019.2-1ubuntu1) ...\r\n",
      "Setting up libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\r\n",
      "Setting up libgl1-mesa-dri:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\r\n",
      "Setting up libegl-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up x11proto-core-dev (2019.2-1ubuntu1) ...\r\n",
      "Setting up libegl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglx-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libxcb1-dev:amd64 (1.14-2) ...\r\n",
      "Setting up libglx0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libx11-dev:amd64 (2:1.6.9-2ubuntu1.6) ...\r\n",
      "Setting up libgl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libglew2.1:amd64 (2.1.0-4) ...\r\n",
      "Setting up libglx-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglu1-mesa:amd64 (9.0.1-1build1) ...\r\n",
      "Setting up libgl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglfw3:amd64 (3.3.2-1) ...\r\n",
      "Setting up libegl-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglu1-mesa-dev:amd64 (9.0.1-1build1) ...\r\n",
      "Setting up libosmesa6-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Setting up libgles-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglvnd-dev:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\r\n",
      "Setting up libglew-dev:amd64 (2.1.0-4) ...\r\n",
      "Setting up libgl1-mesa-dev:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\r\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.2) ...\r\n",
      "Collecting mujoco-py<2.2,>=2.1\r\n",
      "  Downloading mujoco_py-2.1.2.14-py3-none-any.whl (2.4 MB)\r\n",
      "     |████████████████████████████████| 2.4 MB 7.4 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.27.2 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (0.29.24)\r\n",
      "Requirement already satisfied: imageio>=2.1.2 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (2.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (1.19.5)\r\n",
      "Collecting glfw>=1.4.0\r\n",
      "  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\r\n",
      "     |████████████████████████████████| 211 kB 59.4 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: fasteners~=0.15 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (0.16.3)\r\n",
      "Requirement already satisfied: cffi>=1.10 in /opt/conda/lib/python3.7/site-packages (from mujoco-py<2.2,>=2.1) (1.15.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.10->mujoco-py<2.2,>=2.1) (2.21)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fasteners~=0.15->mujoco-py<2.2,>=2.1) (1.16.0)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imageio>=2.1.2->mujoco-py<2.2,>=2.1) (8.2.0)\r\n",
      "Installing collected packages: glfw, mujoco-py\r\n",
      "Successfully installed glfw-2.7.0 mujoco-py-2.1.2.14\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Compiling /opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.pyx because it changed.\n",
      "[1/1] Cythonizing /opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.pyx\n",
      "running build_ext\n",
      "building 'mujoco_py.cymj' extension\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/gl\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/opt/conda/lib/python3.7/site-packages/mujoco_py -I/root/.mujoco/mujoco210/include -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I/opt/conda/lib/python3.7/site-packages/mujoco_py/vendor/egl -I/opt/conda/include/python3.7m -c /opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.c -o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.o -fopenmp -w\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/opt/conda/lib/python3.7/site-packages/mujoco_py -I/root/.mujoco/mujoco210/include -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I/opt/conda/lib/python3.7/site-packages/mujoco_py/vendor/egl -I/opt/conda/include/python3.7m -c /opt/conda/lib/python3.7/site-packages/mujoco_py/gl/eglshim.c -o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/gl/eglshim.o -fopenmp -w\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/lib.linux-x86_64-3.7\n",
      "creating /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py\n",
      "gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/cymj.o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/temp.linux-x86_64-3.7/opt/conda/lib/python3.7/site-packages/mujoco_py/gl/eglshim.o -L/root/.mujoco/mujoco210/bin -Wl,-R/root/.mujoco/mujoco210/bin -lmujoco210 -lglewegl -o /opt/conda/lib/python3.7/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_37_linuxgpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py/cymj.cpython-37m-x86_64-linux-gnu.so -fopenmp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('.mujoco_setup_complete'):\n",
    "  # Get the prereqs\n",
    "  !apt-get -qq update\n",
    "  !apt-get -qq install -y libosmesa6-dev libgl1-mesa-glx libglfw3 libgl1-mesa-dev libglew-dev patchelf\n",
    "  # Get Mujoco\n",
    "  !mkdir ~/.mujoco\n",
    "  !wget -q https://mujoco.org/download/mujoco210-linux-x86_64.tar.gz -O mujoco.tar.gz\n",
    "  !tar -zxf mujoco.tar.gz -C \"$HOME/.mujoco\"\n",
    "  !rm mujoco.tar.gz\n",
    "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
    "  !echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/.mujoco/mujoco210/bin' >> ~/.bashrc \n",
    "  !echo 'export LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libGLEW.so' >> ~/.bashrc \n",
    "  # THE ANNOYING ONE, FORCE IT INTO LDCONFIG SO WE ACTUALLY GET ACCESS TO IT THIS SESSION\n",
    "  !echo \"/root/.mujoco/mujoco210/bin\" > /etc/ld.so.conf.d/mujoco_ld_lib_path.conf\n",
    "  !ldconfig\n",
    "  # Install Mujoco-py\n",
    "  !pip3 install -U 'mujoco-py<2.2,>=2.1'\n",
    "  # run once\n",
    "  !touch .mujoco_setup_complete\n",
    "\n",
    "try:\n",
    "  if _mujoco_run_once:\n",
    "    pass\n",
    "except NameError:\n",
    "  _mujoco_run_once = False\n",
    "if not _mujoco_run_once:\n",
    "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
    "  try:\n",
    "    os.environ['LD_LIBRARY_PATH']=os.environ['LD_LIBRARY_PATH'] + ':/root/.mujoco/mujoco210/bin'\n",
    "  except KeyError:\n",
    "    os.environ['LD_LIBRARY_PATH']='/root/.mujoco/mujoco210/bin'\n",
    "  try:\n",
    "    os.environ['LD_PRELOAD']=os.environ['LD_PRELOAD'] + ':/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
    "  except KeyError:\n",
    "    os.environ['LD_PRELOAD']='/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
    "  # presetup so we don't see output on first env initialization\n",
    "  import mujoco_py\n",
    "  _mujoco_run_once = True\n",
    "#source of this code block : https://gist.github.com/BuildingAtom/3119ac9c595324c8001a7454f23bf8c8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf3dc3e",
   "metadata": {
    "papermill": {
     "duration": 0.071762,
     "end_time": "2024-08-15T17:35:09.855980",
     "exception": false,
     "start_time": "2024-08-15T17:35:09.784218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then import it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee72935f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:35:10.008706Z",
     "iopub.status.busy": "2024-08-15T17:35:10.007760Z",
     "iopub.status.idle": "2024-08-15T17:35:10.010221Z",
     "shell.execute_reply": "2024-08-15T17:35:10.009717Z",
     "shell.execute_reply.started": "2024-08-15T16:07:24.283131Z"
    },
    "papermill": {
     "duration": 0.081212,
     "end_time": "2024-08-15T17:35:10.010358",
     "exception": false,
     "start_time": "2024-08-15T17:35:09.929146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mujoco_py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed907d",
   "metadata": {
    "papermill": {
     "duration": 0.072963,
     "end_time": "2024-08-15T17:35:10.155946",
     "exception": false,
     "start_time": "2024-08-15T17:35:10.082983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## install D4RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66383e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:35:10.306732Z",
     "iopub.status.busy": "2024-08-15T17:35:10.306057Z",
     "iopub.status.idle": "2024-08-15T17:35:53.413823Z",
     "shell.execute_reply": "2024-08-15T17:35:53.413265Z",
     "shell.execute_reply.started": "2024-08-15T16:07:36.905018Z"
    },
    "papermill": {
     "duration": 43.184642,
     "end_time": "2024-08-15T17:35:53.413975",
     "exception": false,
     "start_time": "2024-08-15T17:35:10.229333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting d4rl\r\n",
      "  Cloning https://github.com/Farama-Foundation/d4rl (to revision master) to /tmp/pip-install-1ke54arp/d4rl_e359c5b2d46a4df0b5016d581cf20c7e\r\n",
      "  Running command git clone --filter=blob:none -q https://github.com/Farama-Foundation/d4rl /tmp/pip-install-1ke54arp/d4rl_e359c5b2d46a4df0b5016d581cf20c7e\r\n",
      "  Resolved https://github.com/Farama-Foundation/d4rl to commit 71a9549f2091accff93eeff68f1f3ab2c0e0a288\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting mjrl@ git+https://github.com/aravindr93/mjrl@master#egg=mjrl\r\n",
      "  Cloning https://github.com/aravindr93/mjrl (to revision master) to /tmp/pip-install-1ke54arp/mjrl_9571a2c53f514172b186237f1a8c806e\r\n",
      "  Running command git clone --filter=blob:none -q https://github.com/aravindr93/mjrl /tmp/pip-install-1ke54arp/mjrl_9571a2c53f514172b186237f1a8c806e\r\n",
      "  Resolved https://github.com/aravindr93/mjrl to commit 3871d93763d3b49c4741e6daeaebbc605fe140dc\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: gym<0.24.0 in /opt/conda/lib/python3.7/site-packages (from d4rl) (0.21.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from d4rl) (1.19.5)\r\n",
      "Requirement already satisfied: mujoco_py in /opt/conda/lib/python3.7/site-packages (from d4rl) (2.1.2.14)\r\n",
      "Collecting pybullet\r\n",
      "  Downloading pybullet-3.2.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\r\n",
      "     |████████████████████████████████| 103.2 MB 15 kB/s              \r\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from d4rl) (3.1.0)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from d4rl) (1.1.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from d4rl) (8.0.3)\r\n",
      "Collecting dm_control>=1.0.3\r\n",
      "  Downloading dm_control-1.0.13-py3-none-any.whl (39.3 MB)\r\n",
      "     |████████████████████████████████| 39.3 MB 42.4 MB/s            \r\n",
      "\u001b[?25hCollecting labmaze\r\n",
      "  Downloading labmaze-1.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\r\n",
      "     |████████████████████████████████| 4.9 MB 52.4 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (4.6.4)\r\n",
      "Collecting pyopengl>=3.1.4\r\n",
      "  Downloading PyOpenGL-3.1.7-py3-none-any.whl (2.4 MB)\r\n",
      "     |████████████████████████████████| 2.4 MB 47.5 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: glfw in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (2.7.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (4.62.3)\r\n",
      "Collecting dm-env\r\n",
      "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\r\n",
      "Collecting mujoco>=2.3.6\r\n",
      "  Downloading mujoco-2.3.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\r\n",
      "     |████████████████████████████████| 4.5 MB 48.0 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (3.0.6)\r\n",
      "Requirement already satisfied: dm-tree!=0.1.2 in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (0.1.6)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (2.25.1)\r\n",
      "Requirement already satisfied: setuptools!=50.0.0 in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (59.1.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (1.7.2)\r\n",
      "Collecting protobuf>=3.19.4\r\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\r\n",
      "     |████████████████████████████████| 311 kB 56.1 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from dm_control>=1.0.3->d4rl) (0.15.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /opt/conda/lib/python3.7/site-packages (from gym<0.24.0->d4rl) (4.8.2)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym<0.24.0->d4rl) (2.0.0)\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->d4rl) (1.5.2)\r\n",
      "Requirement already satisfied: imageio>=2.1.2 in /opt/conda/lib/python3.7/site-packages (from mujoco_py->d4rl) (2.9.0)\r\n",
      "Requirement already satisfied: fasteners~=0.15 in /opt/conda/lib/python3.7/site-packages (from mujoco_py->d4rl) (0.16.3)\r\n",
      "Requirement already satisfied: Cython>=0.27.2 in /opt/conda/lib/python3.7/site-packages (from mujoco_py->d4rl) (0.29.24)\r\n",
      "Requirement already satisfied: cffi>=1.10 in /opt/conda/lib/python3.7/site-packages (from mujoco_py->d4rl) (1.15.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.7.0->dm_control>=1.0.3->d4rl) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.10->mujoco_py->d4rl) (2.21)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imageio>=2.1.2->mujoco_py->d4rl) (8.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym<0.24.0->d4rl) (3.10.0.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym<0.24.0->d4rl) (3.6.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->dm_control>=1.0.3->d4rl) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->dm_control>=1.0.3->d4rl) (2021.10.8)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->dm_control>=1.0.3->d4rl) (4.0.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->dm_control>=1.0.3->d4rl) (1.26.7)\r\n",
      "Building wheels for collected packages: d4rl, mjrl\r\n",
      "  Building wheel for d4rl (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for d4rl: filename=D4RL-1.1-py3-none-any.whl size=26432223 sha256=466b537f51c181f9d118136489296090674843f10bf7d89418850cb7bd3df117\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tl1cry18/wheels/e3/6a/07/5d467cea78b4ba39297b0c15128d19e98a88f5bfa00c7d48f8\r\n",
      "  Building wheel for mjrl (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mjrl: filename=mjrl-1.0.0-py3-none-any.whl size=61953 sha256=433b8dc971f0bfcac09b2e2737c5b26d4079a1e5f0d8a135c2fb1b59b59da94e\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tl1cry18/wheels/93/b7/9c/081e42bc27b633708ab9f5b757ffb500b5c0cd2ca52b75b9b0\r\n",
      "Successfully built d4rl mjrl\r\n",
      "Installing collected packages: pyopengl, protobuf, mujoco, labmaze, dm-env, pybullet, mjrl, dm-control, d4rl\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.19.1\r\n",
      "    Uninstalling protobuf-3.19.1:\r\n",
      "      Successfully uninstalled protobuf-3.19.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\r\n",
      "cudf 21.10.1 requires cupy-cuda110, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.4 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "tfx-bsl 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "tfx-bsl 1.4.0 requires protobuf<4,>=3.13, but you have protobuf 4.24.4 which is incompatible.\r\n",
      "tfx-bsl 1.4.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.0 which is incompatible.\r\n",
      "tensorflow 2.6.2 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\r\n",
      "tensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "tensorflow 2.6.2 requires wrapt~=1.12.1, but you have wrapt 1.13.3 which is incompatible.\r\n",
      "tensorflow-transform 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "tensorflow-transform 1.4.0 requires protobuf<4,>=3.13, but you have protobuf 4.24.4 which is incompatible.\r\n",
      "tensorflow-transform 1.4.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.4.0 requires protobuf<4,>=3.13, but you have protobuf 4.24.4 which is incompatible.\r\n",
      "matrixprofile 1.1.10 requires protobuf<4.0.0,>=3.11.2, but you have protobuf 4.24.4 which is incompatible.\r\n",
      "gcsfs 2021.11.0 requires fsspec==2021.11.0, but you have fsspec 2021.11.1 which is incompatible.\r\n",
      "apache-beam 2.34.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\r\n",
      "apache-beam 2.34.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\r\n",
      "apache-beam 2.34.0 requires protobuf<4,>=3.12.2, but you have protobuf 4.24.4 which is incompatible.\r\n",
      "apache-beam 2.34.0 requires pyarrow<6.0.0,>=0.15.1, but you have pyarrow 6.0.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed d4rl-1.1 dm-control-1.0.13 dm-env-1.6 labmaze-1.0.6 mjrl-1.0.0 mujoco-2.3.6 protobuf-4.24.4 pybullet-3.2.6 pyopengl-3.1.7\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# intall d4rl github repo\n",
    "!pip install git+https://github.com/Farama-Foundation/d4rl@master#egg=d4rl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c79b6",
   "metadata": {
    "papermill": {
     "duration": 0.148979,
     "end_time": "2024-08-15T17:35:53.710432",
     "exception": false,
     "start_time": "2024-08-15T17:35:53.561453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## check all the avilable environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445ac6fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:35:54.007764Z",
     "iopub.status.busy": "2024-08-15T17:35:54.007028Z",
     "iopub.status.idle": "2024-08-15T17:35:54.497570Z",
     "shell.execute_reply": "2024-08-15T17:35:54.497023Z",
     "shell.execute_reply.started": "2024-08-15T16:09:07.093958Z"
    },
    "papermill": {
     "duration": 0.643159,
     "end_time": "2024-08-15T17:35:54.497707",
     "exception": false,
     "start_time": "2024-08-15T17:35:53.854548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "/opt/conda/lib/python3.7/site-packages/glfw/__init__.py:914: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Nov 28 2023 23:50:19\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available environments: ['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v0', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Reacher-v2', 'Pusher-v2', 'Thrower-v2', 'Striker-v2', 'InvertedPendulum-v2', 'InvertedDoublePendulum-v2', 'HalfCheetah-v2', 'HalfCheetah-v3', 'Hopper-v2', 'Hopper-v3', 'Swimmer-v2', 'Swimmer-v3', 'Walker2d-v2', 'Walker2d-v3', 'Ant-v2', 'Ant-v3', 'Humanoid-v2', 'Humanoid-v3', 'HumanoidStandup-v2', 'FetchSlide-v1', 'FetchPickAndPlace-v1', 'FetchReach-v1', 'FetchPush-v1', 'HandReach-v0', 'HandManipulateBlockRotateZ-v0', 'HandManipulateBlockRotateZTouchSensors-v0', 'HandManipulateBlockRotateZTouchSensors-v1', 'HandManipulateBlockRotateParallel-v0', 'HandManipulateBlockRotateParallelTouchSensors-v0', 'HandManipulateBlockRotateParallelTouchSensors-v1', 'HandManipulateBlockRotateXYZ-v0', 'HandManipulateBlockRotateXYZTouchSensors-v0', 'HandManipulateBlockRotateXYZTouchSensors-v1', 'HandManipulateBlockFull-v0', 'HandManipulateBlock-v0', 'HandManipulateBlockTouchSensors-v0', 'HandManipulateBlockTouchSensors-v1', 'HandManipulateEggRotate-v0', 'HandManipulateEggRotateTouchSensors-v0', 'HandManipulateEggRotateTouchSensors-v1', 'HandManipulateEggFull-v0', 'HandManipulateEgg-v0', 'HandManipulateEggTouchSensors-v0', 'HandManipulateEggTouchSensors-v1', 'HandManipulatePenRotate-v0', 'HandManipulatePenRotateTouchSensors-v0', 'HandManipulatePenRotateTouchSensors-v1', 'HandManipulatePenFull-v0', 'HandManipulatePen-v0', 'HandManipulatePenTouchSensors-v0', 'HandManipulatePenTouchSensors-v1', 'FetchSlideDense-v1', 'FetchPickAndPlaceDense-v1', 'FetchReachDense-v1', 'FetchPushDense-v1', 'HandReachDense-v0', 'HandManipulateBlockRotateZDense-v0', 'HandManipulateBlockRotateZTouchSensorsDense-v0', 'HandManipulateBlockRotateZTouchSensorsDense-v1', 'HandManipulateBlockRotateParallelDense-v0', 'HandManipulateBlockRotateParallelTouchSensorsDense-v0', 'HandManipulateBlockRotateParallelTouchSensorsDense-v1', 'HandManipulateBlockRotateXYZDense-v0', 'HandManipulateBlockRotateXYZTouchSensorsDense-v0', 'HandManipulateBlockRotateXYZTouchSensorsDense-v1', 'HandManipulateBlockFullDense-v0', 'HandManipulateBlockDense-v0', 'HandManipulateBlockTouchSensorsDense-v0', 'HandManipulateBlockTouchSensorsDense-v1', 'HandManipulateEggRotateDense-v0', 'HandManipulateEggRotateTouchSensorsDense-v0', 'HandManipulateEggRotateTouchSensorsDense-v1', 'HandManipulateEggFullDense-v0', 'HandManipulateEggDense-v0', 'HandManipulateEggTouchSensorsDense-v0', 'HandManipulateEggTouchSensorsDense-v1', 'HandManipulatePenRotateDense-v0', 'HandManipulatePenRotateTouchSensorsDense-v0', 'HandManipulatePenRotateTouchSensorsDense-v1', 'HandManipulatePenFullDense-v0', 'HandManipulatePenDense-v0', 'HandManipulatePenTouchSensorsDense-v0', 'HandManipulatePenTouchSensorsDense-v1', 'CubeCrash-v0', 'CubeCrashSparse-v0', 'CubeCrashScreenBecomesBlack-v0', 'MemorizeDigits-v0', 'antmaze-umaze-v0', 'antmaze-umaze-diverse-v0', 'antmaze-medium-play-v0', 'antmaze-medium-diverse-v0', 'antmaze-large-diverse-v0', 'antmaze-large-play-v0', 'antmaze-umaze-v1', 'antmaze-umaze-diverse-v1', 'antmaze-medium-play-v1', 'antmaze-medium-diverse-v1', 'antmaze-large-diverse-v1', 'antmaze-large-play-v1', 'antmaze-eval-umaze-v0', 'antmaze-eval-umaze-diverse-v0', 'antmaze-eval-medium-play-v0', 'antmaze-eval-medium-diverse-v0', 'antmaze-eval-large-diverse-v0', 'antmaze-eval-large-play-v0', 'antmaze-umaze-v2', 'antmaze-umaze-diverse-v2', 'antmaze-medium-play-v2', 'antmaze-medium-diverse-v2', 'antmaze-large-diverse-v2', 'antmaze-large-play-v2', 'mjrl_point_mass-v0', 'mjrl_swimmer-v0', 'mjrl_reacher_7dof-v0', 'mjrl_peg_insertion-v0', 'hammer-human-v1', 'hammer-human-longhorizon-v1', 'hammer-expert-v1', 'hammer-cloned-v1', 'pen-human-v1', 'pen-human-longhorizon-v1', 'pen-expert-v1', 'pen-cloned-v1', 'relocate-human-v1', 'relocate-human-longhorizon-v1', 'relocate-expert-v1', 'relocate-cloned-v1', 'door-human-v1', 'door-human-longhorizon-v1', 'door-expert-v1', 'door-cloned-v1', 'door-v0', 'door-human-v0', 'door-human-longhorizon-v0', 'door-cloned-v0', 'door-expert-v0', 'hammer-v0', 'hammer-human-v0', 'hammer-human-longhorizon-v0', 'hammer-cloned-v0', 'hammer-expert-v0', 'pen-v0', 'pen-human-v0', 'pen-human-longhorizon-v0', 'pen-cloned-v0', 'pen-expert-v0', 'relocate-v0', 'relocate-human-v0', 'relocate-human-longhorizon-v0', 'relocate-cloned-v0', 'relocate-expert-v0', 'maze2d-open-v0', 'maze2d-umaze-v0', 'maze2d-medium-v0', 'maze2d-large-v0', 'maze2d-umaze-v1', 'maze2d-medium-v1', 'maze2d-large-v1', 'maze2d-eval-umaze-v1', 'maze2d-eval-medium-v1', 'maze2d-eval-large-v1', 'maze2d-open-dense-v0', 'maze2d-umaze-dense-v0', 'maze2d-medium-dense-v0', 'maze2d-large-dense-v0', 'maze2d-umaze-dense-v1', 'maze2d-medium-dense-v1', 'maze2d-large-dense-v1', 'maze2d-eval-umaze-dense-v1', 'maze2d-eval-medium-dense-v1', 'maze2d-eval-large-dense-v1', 'minigrid-fourrooms-v0', 'minigrid-fourrooms-random-v0', 'hopper-random-v1', 'hopper-random-v2', 'hopper-medium-v1', 'hopper-medium-v2', 'hopper-expert-v1', 'hopper-expert-v2', 'hopper-medium-expert-v1', 'hopper-medium-expert-v2', 'hopper-medium-replay-v1', 'hopper-medium-replay-v2', 'hopper-full-replay-v1', 'hopper-full-replay-v2', 'halfcheetah-random-v1', 'halfcheetah-random-v2', 'halfcheetah-medium-v1', 'halfcheetah-medium-v2', 'halfcheetah-expert-v1', 'halfcheetah-expert-v2', 'halfcheetah-medium-expert-v1', 'halfcheetah-medium-expert-v2', 'halfcheetah-medium-replay-v1', 'halfcheetah-medium-replay-v2', 'halfcheetah-full-replay-v1', 'halfcheetah-full-replay-v2', 'ant-random-v1', 'ant-random-v2', 'ant-medium-v1', 'ant-medium-v2', 'ant-expert-v1', 'ant-expert-v2', 'ant-medium-expert-v1', 'ant-medium-expert-v2', 'ant-medium-replay-v1', 'ant-medium-replay-v2', 'ant-full-replay-v1', 'ant-full-replay-v2', 'walker2d-random-v1', 'walker2d-random-v2', 'walker2d-medium-v1', 'walker2d-medium-v2', 'walker2d-expert-v1', 'walker2d-expert-v2', 'walker2d-medium-expert-v1', 'walker2d-medium-expert-v2', 'walker2d-medium-replay-v1', 'walker2d-medium-replay-v2', 'walker2d-full-replay-v1', 'walker2d-full-replay-v2', 'hopper-medium-v0', 'halfcheetah-medium-v0', 'walker2d-medium-v0', 'hopper-expert-v0', 'halfcheetah-expert-v0', 'walker2d-expert-v0', 'hopper-random-v0', 'halfcheetah-random-v0', 'walker2d-random-v0', 'hopper-medium-replay-v0', 'walker2d-medium-replay-v0', 'halfcheetah-medium-replay-v0', 'walker2d-medium-expert-v0', 'halfcheetah-medium-expert-v0', 'hopper-medium-expert-v0', 'ant-medium-expert-v0', 'ant-medium-replay-v0', 'ant-medium-v0', 'ant-random-v0', 'ant-expert-v0', 'ant-random-expert-v0', 'kitchen_relax-v1', 'kitchen-complete-v0', 'kitchen-partial-v0', 'kitchen-mixed-v0', 'HumanoidDeepMimicBackflipBulletEnv-v1', 'HumanoidDeepMimicWalkBulletEnv-v1', 'CartPoleBulletEnv-v1', 'CartPoleContinuousBulletEnv-v0', 'MinitaurBulletEnv-v0', 'MinitaurBulletDuckEnv-v0', 'MinitaurExtendedEnv-v0', 'MinitaurReactiveEnv-v0', 'MinitaurBallGymEnv-v0', 'MinitaurTrottingEnv-v0', 'MinitaurStandGymEnv-v0', 'MinitaurAlternatingLegsEnv-v0', 'MinitaurFourLegStandEnv-v0', 'RacecarBulletEnv-v0', 'RacecarZedBulletEnv-v0', 'KukaBulletEnv-v0', 'KukaCamBulletEnv-v0', 'KukaDiverseObjectGrasping-v0', 'InvertedPendulumBulletEnv-v0', 'InvertedDoublePendulumBulletEnv-v0', 'InvertedPendulumSwingupBulletEnv-v0', 'ReacherBulletEnv-v0', 'PusherBulletEnv-v0', 'ThrowerBulletEnv-v0', 'Walker2DBulletEnv-v0', 'HalfCheetahBulletEnv-v0', 'AntBulletEnv-v0', 'HopperBulletEnv-v0', 'HumanoidBulletEnv-v0', 'HumanoidFlagrunBulletEnv-v0', 'HumanoidFlagrunHarderBulletEnv-v0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: GymBullet failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "numpy.core.multiarray failed to import\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import d4rl\n",
    "\n",
    "# List all available environments to see if Maze2D is included\n",
    "envs = gym.envs.registry.all()\n",
    "env_names = [env_spec.id for env_spec in envs]\n",
    "print(\"Available environments:\", env_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10289a",
   "metadata": {
    "papermill": {
     "duration": 0.146143,
     "end_time": "2024-08-15T17:35:54.791907",
     "exception": false,
     "start_time": "2024-08-15T17:35:54.645764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## download the dataset for the hopper environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a941ed1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:35:55.098724Z",
     "iopub.status.busy": "2024-08-15T17:35:55.090635Z",
     "iopub.status.idle": "2024-08-15T17:35:59.559987Z",
     "shell.execute_reply": "2024-08-15T17:35:59.559501Z",
     "shell.execute_reply.started": "2024-08-15T16:12:55.845360Z"
    },
    "papermill": {
     "duration": 4.620878,
     "end_time": "2024-08-15T17:35:59.560126",
     "exception": false,
     "start_time": "2024-08-15T17:35:54.939248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset [ 1.25123292e+00 -3.13952359e-03 -3.65024003e-03 -3.39303411e-03\n",
      "  4.89516024e-03 -4.76585622e-03  4.32292767e-03  1.10091968e-03\n",
      " -4.47141261e-03 -1.77421113e-03  3.27490110e-05]\n",
      "step (array([ 1.25087468, -0.00252392, -0.0041826 , -0.00137263,  0.00763282,\n",
      "        0.04880493, -0.09393581,  0.15263879, -0.12839665,  0.50633612,\n",
      "        0.68355802]), 1.0216555537807812, False, {})\n",
      "Downloading dataset: http://rail.eecs.berkeley.edu/datasets/offline_rl/gym_mujoco_v2/hopper_expert-v2.hdf5 to /root/.d4rl/datasets/hopper_expert-v2.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|██████████| 21/21 [00:01<00:00, 15.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['actions', 'infos/action_log_probs', 'infos/qpos', 'infos/qvel', 'metadata/algorithm', 'metadata/iteration', 'metadata/policy/fc0/bias', 'metadata/policy/fc0/weight', 'metadata/policy/fc1/bias', 'metadata/policy/fc1/weight', 'metadata/policy/last_fc/bias', 'metadata/policy/last_fc/weight', 'metadata/policy/last_fc_log_std/bias', 'metadata/policy/last_fc_log_std/weight', 'metadata/policy/nonlinearity', 'metadata/policy/output_distribution', 'next_observations', 'observations', 'rewards', 'terminals', 'timeouts'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the environment\n",
    "env = gym.make('hopper-expert-v2') #gym.make('maze2d-umaze-v1')\n",
    "\n",
    "print(\"reset\",env.reset())\n",
    "print(\"step\",env.step(env.action_space.sample()))\n",
    "\n",
    "#get the dataset for hopper\n",
    "dataset = env.get_dataset()\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7085e444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:35:59.871639Z",
     "iopub.status.busy": "2024-08-15T17:35:59.870771Z",
     "iopub.status.idle": "2024-08-15T17:35:59.874193Z",
     "shell.execute_reply": "2024-08-15T17:35:59.874750Z",
     "shell.execute_reply.started": "2024-08-15T16:14:28.319815Z"
    },
    "papermill": {
     "duration": 0.160442,
     "end_time": "2024-08-15T17:35:59.874922",
     "exception": false,
     "start_time": "2024-08-15T17:35:59.714480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state [ 1.24991559e+00 -4.22690992e-03 -7.24640443e-03  3.33163016e-04\n",
      "  9.55415893e-03 -5.04915988e-02 -1.45906028e-01 -5.77573198e-01\n",
      " -6.37014206e-01 -7.93385434e-02 -2.02180636e-01] \n",
      " reward  0.998299331119719 \n",
      " done False \n",
      " info {}\n"
     ]
    }
   ],
   "source": [
    "state, reward, done, info=env.step(env.action_space.sample())\n",
    "print(\"state\",state, \"\\n reward \", reward, \"\\n done\", done, \"\\n info\", info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d4ff3",
   "metadata": {
    "papermill": {
     "duration": 0.148887,
     "end_time": "2024-08-15T17:36:00.183044",
     "exception": false,
     "start_time": "2024-08-15T17:36:00.034157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## let's check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "749f75b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:00.488857Z",
     "iopub.status.busy": "2024-08-15T17:36:00.487947Z",
     "iopub.status.idle": "2024-08-15T17:36:00.492059Z",
     "shell.execute_reply": "2024-08-15T17:36:00.492648Z",
     "shell.execute_reply.started": "2024-08-15T16:15:05.274195Z"
    },
    "papermill": {
     "duration": 0.159188,
     "end_time": "2024-08-15T17:36:00.492825",
     "exception": false,
     "start_time": "2024-08-15T17:36:00.333637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['actions', 'infos/action_log_probs', 'infos/qpos', 'infos/qvel', 'metadata/algorithm', 'metadata/iteration', 'metadata/policy/fc0/bias', 'metadata/policy/fc0/weight', 'metadata/policy/fc1/bias', 'metadata/policy/fc1/weight', 'metadata/policy/last_fc/bias', 'metadata/policy/last_fc/weight', 'metadata/policy/last_fc_log_std/bias', 'metadata/policy/last_fc_log_std/weight', 'metadata/policy/nonlinearity', 'metadata/policy/output_distribution', 'next_observations', 'observations', 'rewards', 'terminals', 'timeouts'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(env.observation_space.shape)\n",
    "#print the dataset attributes\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376740a2",
   "metadata": {
    "papermill": {
     "duration": 0.152233,
     "end_time": "2024-08-15T17:36:00.797073",
     "exception": false,
     "start_time": "2024-08-15T17:36:00.644840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### attributes of the dataset\n",
    "* actions: Actions taken by the agent.\n",
    "* infos/action_log_probs: Log probabilities of the taken actions.\n",
    "* infos/qpos: Generalized positions of the Hopper's joints and body parts.\n",
    "* infos/qvel: Generalized velocities of the Hopper's joints and body parts.\n",
    "* metadata/algorithm: The algorithm used to generate expert data.\n",
    "* metadata/iteration: Iteration number when the data was collected.\n",
    "* metadata/policy/fc0/bias: Bias of the first fully connected layer in the policy network.\n",
    "* metadata/policy/fc0/weight: Weights of the first fully connected layer in the policy network.\n",
    "* metadata/policy/fc1/bias: Bias of the second fully connected layer in the policy network.\n",
    "* metadata/policy/fc1/weight: Weights of the second fully connected layer in the policy network.\n",
    "* metadata/policy/last_fc/bias: Bias of the last fully connected layer in the policy network.\n",
    "* metadata/policy/last_fc/weight: Weights of the last fully connected layer in the policy network.\n",
    "* metadata/policy/last_fc_log_std/bias: Bias for the log standard deviation in the last layer.\n",
    "* metadata/policy/last_fc_log_std/weight: Weights for the log standard deviation in the last layer.\n",
    "* metadata/policy/nonlinearity: Type of nonlinearity used in the policy network.\n",
    "* metadata/policy/output_distribution: Distribution type for the policy's output.\n",
    "* next_observations: Observations after the agent takes an action.\n",
    "* observations: Observations before the agent takes an action.\n",
    "* rewards: Rewards received after actions are taken.\n",
    "* terminals: Indicates if an episode ended (True/False).\n",
    "* timeouts: Indicates if an episode ended due to a time limit (True/False).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2dd132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:01.110292Z",
     "iopub.status.busy": "2024-08-15T17:36:01.109642Z",
     "iopub.status.idle": "2024-08-15T17:36:01.115445Z",
     "shell.execute_reply": "2024-08-15T17:36:01.114879Z",
     "shell.execute_reply.started": "2024-08-15T16:15:53.477014Z"
    },
    "papermill": {
     "duration": 0.165866,
     "end_time": "2024-08-15T17:36:01.115605",
     "exception": false,
     "start_time": "2024-08-15T17:36:00.949739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of our columns/attributes: actions= (1000000, 3)  observations= (1000000, 11)  rewards= (1000000,)\n",
      "next_observations= (1000000, 11)  terminals= (1000000,)  timeouts= (1000000,) done= (1000000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#unpack the dataset\n",
    "actions= dataset['actions'] # Actions taken by the agent\n",
    "observations= dataset['observations'] # The observations or states seen by the agent.\n",
    "rewards= dataset['rewards'] #The reward received after each action. .reshape(-1, 1)\n",
    "next_observations= dataset['next_observations'] #next observations after the agent takes an action\n",
    "terminals= dataset['terminals'] #Indicates if the episode ended in an unhealty way (1 if ended, 0 otherwise) \n",
    "timeouts= dataset ['timeouts'] #Indicates if the episode ended due to a timeout.\n",
    "#we will take either the episode being done or timeout both as dones since we don'thave done in the dataset\n",
    "dones= np.logical_or(terminals, timeouts)\n",
    "print(\"shapes of our columns/attributes: actions=\", actions.shape, \" observations=\", observations.shape, \" rewards=\", rewards.shape)\n",
    "print(\"next_observations=\", next_observations.shape, \" terminals=\", terminals.shape,\" timeouts=\", timeouts.shape, \"done=\", dones.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d08bd95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:01.459051Z",
     "iopub.status.busy": "2024-08-15T17:36:01.458138Z",
     "iopub.status.idle": "2024-08-15T17:36:03.016530Z",
     "shell.execute_reply": "2024-08-15T17:36:03.017167Z",
     "shell.execute_reply.started": "2024-08-15T17:10:18.139685Z"
    },
    "papermill": {
     "duration": 1.751248,
     "end_time": "2024-08-15T17:36:03.017400",
     "exception": false,
     "start_time": "2024-08-15T17:36:01.266152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, observations, actions, next_observations, rewards, dones):\n",
    "        super().__init__()\n",
    "        # Extract data\n",
    "        self.observations = torch.tensor(observations, dtype=torch.float32)\n",
    "        self.actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        self.rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        self.next_observations = torch.tensor(next_observations, dtype=torch.float32)\n",
    "        self.dones= torch.tensor(dones,dtype= torch.bool )\n",
    "        #self.timeouts= torch.tensor(timeouts, dtype= torch.bool)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.observations[idx], self.actions[idx], self.next_observations[idx], self.rewards[idx], self.dones[idx]\n",
    "\n",
    "whole_dataset= CustomDataset( observations, actions, rewards, next_observations,  dones)\n",
    "\n",
    "print(len(whole_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00132f72",
   "metadata": {
    "papermill": {
     "duration": 0.163241,
     "end_time": "2024-08-15T17:36:03.356311",
     "exception": false,
     "start_time": "2024-08-15T17:36:03.193070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491ef2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:03.683514Z",
     "iopub.status.busy": "2024-08-15T17:36:03.682272Z",
     "iopub.status.idle": "2024-08-15T17:36:03.685172Z",
     "shell.execute_reply": "2024-08-15T17:36:03.684519Z",
     "shell.execute_reply.started": "2024-08-15T16:16:35.071733Z"
    },
    "papermill": {
     "duration": 0.168481,
     "end_time": "2024-08-15T17:36:03.685321",
     "exception": false,
     "start_time": "2024-08-15T17:36:03.516840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 120\n",
    "data_loader= DataLoader(whole_dataset, batch_size, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c639bd",
   "metadata": {
    "papermill": {
     "duration": 0.162901,
     "end_time": "2024-08-15T17:36:04.011575",
     "exception": false,
     "start_time": "2024-08-15T17:36:03.848674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# create the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3138f0",
   "metadata": {
    "papermill": {
     "duration": 0.160695,
     "end_time": "2024-08-15T17:36:04.334287",
     "exception": false,
     "start_time": "2024-08-15T17:36:04.173592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The actor responsible for choosing an action given a specific state \"policy network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5787234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:04.672957Z",
     "iopub.status.busy": "2024-08-15T17:36:04.671800Z",
     "iopub.status.idle": "2024-08-15T17:36:04.674659Z",
     "shell.execute_reply": "2024-08-15T17:36:04.674110Z",
     "shell.execute_reply.started": "2024-08-15T16:16:38.264290Z"
    },
    "papermill": {
     "duration": 0.178616,
     "end_time": "2024-08-15T17:36:04.674816",
     "exception": false,
     "start_time": "2024-08-15T17:36:04.496200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size= 32, standard_deviation_min= -10, standard_deviation_max= 10):\n",
    "        \"\"\"\n",
    "        state_size: (input size).\n",
    "        action_size: (output size).\n",
    "        hidden_size: Number of neurons in the hidden layers (default 32).\n",
    "        standard_deviation_min and standard_deviation_max: values used to clamp the log standard deviation of the policy's action distribution to prevent it from becoming too high or too low.\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.standard_deviation_min= standard_deviation_min\n",
    "        self.standard_deviation_max= standard_deviation_max\n",
    "        self.lin1= nn.Linear(state_size, hidden_size)\n",
    "        self.lin2= nn.Linear(hidden_size, hidden_size)\n",
    "        #output Linear layers to get the mean (mu) and the log standard deviation (log_sigma) of the action distribution.\n",
    "        self.mu= nn.Linear(hidden_size, action_size) # mean\n",
    "        self.log_sigma= nn.Linear(hidden_size, action_size) #standard deviation\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x= F.relu(self.lin2(F.relu(self.lin1(state))))\n",
    "        \n",
    "        mu = torch.tanh(self.mu(x)) #The mean is passed through a tanh activation to keep the action within a certain range.\n",
    "        \n",
    "        log_sigma= self.log_sigma(x)\n",
    "        log_sigma = torch.clamp(log_sigma, self.standard_deviation_min, self.standard_deviation_max)\n",
    "        return mu, log_sigma\n",
    "    \n",
    "    def evaluate(self, state):\n",
    "        mu, log_sigma= self.forward(state) \n",
    "        sigma= log_sigma.exp()\n",
    "        normal_distribution= Normal(mu, sigma) #create normal distriution\n",
    "        \n",
    "        action= normal_distribution.sample() #get an action from the distriution\n",
    "        return action, normal_distribution \n",
    "    \n",
    "    def get_action(self, state): #to be used in the evaluation phase\n",
    "        mu, log_sigma= self.forward(state) \n",
    "        sigma= log_sigma.exp()\n",
    "        normal_distribution= Normal(mu, sigma) #create normal distriution\n",
    "        \n",
    "        action= normal_distribution.sample() #get an action from the distriution\n",
    "        return action.detach().cpu()\n",
    "    \n",
    "    def get_deterministic_action(self, state):\n",
    "        mu, _= self.forward(state)\n",
    "        return mu.detach().cpu()\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54254be",
   "metadata": {
    "papermill": {
     "duration": 0.171243,
     "end_time": "2024-08-15T17:36:05.007804",
     "exception": false,
     "start_time": "2024-08-15T17:36:04.836561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### the critic estimates the Q-value, which is the expected return for taking a particular action in a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9996d284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:05.344893Z",
     "iopub.status.busy": "2024-08-15T17:36:05.344096Z",
     "iopub.status.idle": "2024-08-15T17:36:05.347223Z",
     "shell.execute_reply": "2024-08-15T17:36:05.346558Z",
     "shell.execute_reply.started": "2024-08-15T16:16:39.249725Z"
    },
    "papermill": {
     "duration": 0.177431,
     "end_time": "2024-08-15T17:36:05.347400",
     "exception": false,
     "start_time": "2024-08-15T17:36:05.169969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size= 32,seed= 1):\n",
    "        super(Critic, self).__init__()\n",
    "        torch.manual_seed(1)\n",
    "        self.lin1= nn.Linear(state_size+action_size, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3= nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        #print(\"Critic\", state.shape, action.shape)\n",
    "        x= torch.cat((state, action), dim=-1)\n",
    "        #print(x.shape)\n",
    "        x= F.relu(self.lin2(F.relu(self.lin1(x))))\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c29fc7",
   "metadata": {
    "papermill": {
     "duration": 0.164837,
     "end_time": "2024-08-15T17:36:05.677793",
     "exception": false,
     "start_time": "2024-08-15T17:36:05.512956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  the value estimates the expected return from a state, independent of any specific action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daa11b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:06.019879Z",
     "iopub.status.busy": "2024-08-15T17:36:06.018780Z",
     "iopub.status.idle": "2024-08-15T17:36:06.021075Z",
     "shell.execute_reply": "2024-08-15T17:36:06.021610Z",
     "shell.execute_reply.started": "2024-08-15T16:16:39.965029Z"
    },
    "papermill": {
     "duration": 0.178893,
     "end_time": "2024-08-15T17:36:06.021805",
     "exception": false,
     "start_time": "2024-08-15T17:36:05.842912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Value(nn.Module):\n",
    "    def __init__(self, state_size, hidden_size= 32):\n",
    "        super(Value, self).__init__()\n",
    "        self.lin1= nn.Linear(state_size, hidden_size)\n",
    "        self.lin2= nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3= nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x= F.relu(self.lin2(F.relu(self.lin1(state))))\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b25fb8",
   "metadata": {
    "papermill": {
     "duration": 0.152962,
     "end_time": "2024-08-15T17:36:06.341183",
     "exception": false,
     "start_time": "2024-08-15T17:36:06.188221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df881e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:06.754455Z",
     "iopub.status.busy": "2024-08-15T17:36:06.748552Z",
     "iopub.status.idle": "2024-08-15T17:36:06.760806Z",
     "shell.execute_reply": "2024-08-15T17:36:06.760030Z",
     "shell.execute_reply.started": "2024-08-15T16:16:40.776820Z"
    },
    "papermill": {
     "duration": 0.245922,
     "end_time": "2024-08-15T17:36:06.760958",
     "exception": false,
     "start_time": "2024-08-15T17:36:06.515036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size, batch_size, device):\n",
    "        self.device= device\n",
    "        self.memory= deque(maxlen= max_size)\n",
    "        self.batch_size= batch_size\n",
    "        #define expericences tuple\n",
    "        self.experience= namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e= self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "        \n",
    "    def sample(self):\n",
    "        #sample randome experiences from memory to train the model i=on it\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        #unpacked them into seperate tensors\n",
    "        states = torch.from_numpy(np.stack([e.state for e in experiences if e is not None])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.stack([e.next_state for e in experiences if e is not None])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
    "        return (states, actions, rewards, next_states, terminals,timeouts )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1fe3370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:07.145999Z",
     "iopub.status.busy": "2024-08-15T17:36:07.144944Z",
     "iopub.status.idle": "2024-08-15T17:36:07.175464Z",
     "shell.execute_reply": "2024-08-15T17:36:07.174317Z",
     "shell.execute_reply.started": "2024-08-15T16:16:41.273601Z"
    },
    "papermill": {
     "duration": 0.210529,
     "end_time": "2024-08-15T17:36:07.175658",
     "exception": false,
     "start_time": "2024-08-15T17:36:06.965129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "class Implicit_Q_learning(nn.Module):\n",
    "    def __init__(self, state_size, action_size, lr, hidden_size, tau, temperature, expectile, device):\n",
    "        super(Implicit_Q_learning, self).__init__()\n",
    "        self.state_size= state_size\n",
    "        self.action_size= action_size\n",
    "        self.lr= lr\n",
    "        self.hidden_size= hidden_size\n",
    "        self.tau= tau #update parameter for the target netwrok\n",
    "        self.device = device\n",
    "        self.temperature= torch.FloatTensor([temperature]).to(self.device)\n",
    "        self.expectile= torch.FloatTensor([expectile]).to(self.device)\n",
    "        self.gamma = torch.FloatTensor([0.99]).to(device) #to compute the Q-values\n",
    "        self.clip_grad_param = 1\n",
    "\n",
    "        #____define the neuralnetwroks____\n",
    "        # Actor_network: outputs actions based on the state.\n",
    "        self.actor_local= Actor(self.state_size, self.action_size, self.hidden_size).to(self.device)\n",
    "        self.actor_optimizer= optim.Adam(self.actor_local.parameters(), lr= self.lr)\n",
    "\n",
    "        # Critic_networks: Two Q-value networks to estimate the value of state-action pairs.\n",
    "        self.critic1= Critic(self.state_size, self.action_size, self.hidden_size, seed= 2).to(self.device)\n",
    "        self.critic2= Critic(self.state_size, self.action_size, self.hidden_size, seed= 1).to(self.device)\n",
    "        assert self.critic1.parameters() != self.critic2.parameters()\n",
    "\n",
    "        self.critic1_optimizer = optim.Adam(self.critic1.parameters(), lr=self.lr)\n",
    "        self.critic2_optimizer = optim.Adam(self.critic2.parameters(), lr=self.lr) \n",
    "\n",
    "        #Target networks for stability, which slowly track the critic networks.\n",
    "        self.critic1_target = Critic(self.state_size, self.action_size, self.hidden_size).to(self.device)\n",
    "        self.critic1_target.load_state_dict(self.critic1.state_dict())\n",
    "\n",
    "        self.critic2_target = Critic(self.state_size, self.action_size, self.hidden_size).to(self.device)\n",
    "        self.critic2_target.load_state_dict(self.critic2.state_dict())\n",
    "\n",
    "        #Value_network: estimates the value of a state independently of the action.\n",
    "        self.value_net = Value(self.state_size, self.hidden_size).to(self.device)\n",
    "        self.value_optimizer = optim.Adam(self.value_net.parameters(), lr=self.lr)\n",
    "        \n",
    "    def get_action(self, state, eval= False):\n",
    "        state= torch.from_numpy(state).float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if eval:\n",
    "                action = self.actor_local.get_deterministic_action(state)\n",
    "            else:\n",
    "                action = self.actor_local.get_action(state)\n",
    "        return action.numpy()\n",
    "    \n",
    "    def calc_policy_loss(self, states, actions):\n",
    "        with torch.no_grad():\n",
    "            v = self.value_net(states)\n",
    "            q1 = self.critic1_target(states, actions)\n",
    "            q2 = self.critic2_target(states, actions)\n",
    "            min_Q = torch.min(q1,q2)\n",
    "\n",
    "        exp_a = torch.exp((min_Q - v) * self.temperature)\n",
    "        exp_a = torch.min(exp_a, torch.FloatTensor([100.0]).to(states.device))\n",
    "\n",
    "        _, dist = self.actor_local.evaluate(states)\n",
    "        log_probs = dist.log_prob(actions)\n",
    "        actor_loss = -(exp_a * log_probs).mean()\n",
    "\n",
    "        return actor_loss\n",
    "    \n",
    "    def calc_value_loss(self, states, actions):\n",
    "        with torch.no_grad():\n",
    "            q1 = self.critic1_target(states, actions)   \n",
    "            q2 = self.critic2_target(states, actions)\n",
    "            min_Q = torch.min(q1,q2)\n",
    "        \n",
    "        value = self.value_net(states)\n",
    "        value_loss = loss(min_Q - value, self.expectile).mean()\n",
    "        return value_loss\n",
    "    \n",
    "    def calc_q_loss(self, states, actions, rewards, dones, next_states):\n",
    "        with torch.no_grad():\n",
    "            next_v = self.value_net(next_states)\n",
    "            dones = dones.float()\n",
    "            q_target = rewards + (self.gamma * (1 - dones) * next_v) \n",
    "            #q_target = rewards + (self.gamma * (1 - terminals) * (1 - timeouts) * next_v)\n",
    "\n",
    "\n",
    "        q1 = self.critic1(states, actions)\n",
    "        q2 = self.critic2(states, actions)\n",
    "        critic1_loss = ((q1 - q_target)**2).mean() \n",
    "        critic2_loss = ((q2 - q_target)**2).mean()\n",
    "        return critic1_loss, critic2_loss\n",
    "\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        states, actions, rewards, next_states,  dones  = experiences\n",
    "\n",
    "        self.value_optimizer.zero_grad()\n",
    "        #print(states, actions)\n",
    "        #print(states.shape, actions.shape)\n",
    "        value_loss = self.calc_value_loss(states, actions)\n",
    "        value_loss.backward()\n",
    "        self.value_optimizer.step()\n",
    "\n",
    "        actor_loss = self.calc_policy_loss(states, actions)\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        critic1_loss, critic2_loss = self.calc_q_loss(states, actions, rewards, dones, next_states)\n",
    "\n",
    "        # critic 1\n",
    "        self.critic1_optimizer.zero_grad()\n",
    "        critic1_loss.backward()\n",
    "        clip_grad_norm_(self.critic1.parameters(), self.clip_grad_param)\n",
    "        self.critic1_optimizer.step()\n",
    "        # critic 2\n",
    "        self.critic2_optimizer.zero_grad()\n",
    "        critic2_loss.backward()\n",
    "        clip_grad_norm_(self.critic2.parameters(), self.clip_grad_param)\n",
    "        self.critic2_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic1, self.critic1_target)\n",
    "        self.soft_update(self.critic2, self.critic2_target)\n",
    "        \n",
    "        return actor_loss.item(), critic1_loss.item(), critic2_loss.item(), value_loss.item()\n",
    "\n",
    "    def soft_update(self, local_model , target_model):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(self.tau*local_param.data + (1.0-self.tau)*target_param.data)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d472f5cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:07.544404Z",
     "iopub.status.busy": "2024-08-15T17:36:07.499177Z",
     "iopub.status.idle": "2024-08-15T17:36:07.565703Z",
     "shell.execute_reply": "2024-08-15T17:36:07.566245Z",
     "shell.execute_reply.started": "2024-08-15T16:18:52.446926Z"
    },
    "papermill": {
     "duration": 0.227998,
     "end_time": "2024-08-15T17:36:07.566507",
     "exception": false,
     "start_time": "2024-08-15T17:36:07.338509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "run_name= \"IQL\"\n",
    "env_name= \"hopper-expert-v2\" # environment name\n",
    "episodes= 100 #number of episodes\n",
    "seed= 1 \n",
    "save_every= 10 #save the network every x epochs\n",
    "batch_size = 120\n",
    "hidden_size= 256\n",
    "learning_rate= 3e-4\n",
    "temperature= 3\n",
    "expectile= 0.7\n",
    "tau= 5e-3\n",
    "eval_every= 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#define the train loader\n",
    "dataloader= DataLoader(whole_dataset, batch_size, shuffle= True)\n",
    "\n",
    "#the training loop\n",
    "#set the seeds\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "#define an environment\n",
    "env = gym.make('hopper-expert-v2') \n",
    "#set the seed for the action space\n",
    "env.action_space.seed(seed)\n",
    "\n",
    "batches = 0\n",
    "average10 = deque(maxlen=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c26458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:07.885250Z",
     "iopub.status.busy": "2024-08-15T17:36:07.884593Z",
     "iopub.status.idle": "2024-08-15T17:36:08.405293Z",
     "shell.execute_reply": "2024-08-15T17:36:08.404732Z",
     "shell.execute_reply.started": "2024-08-15T16:18:53.001352Z"
    },
    "papermill": {
     "duration": 0.683596,
     "end_time": "2024-08-15T17:36:08.405473",
     "exception": false,
     "start_time": "2024-08-15T17:36:07.721877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "def save(save_name, model, wandb, ep=None):\n",
    "    save_dir = './trained_models/' \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    save_path = os.path.join(save_dir, run_name + save_name)\n",
    "    if ep is not None:\n",
    "        save_path += str(ep) + \".pth\"\n",
    "    else:\n",
    "        save_path += \".pth\"\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    wandb.save(save_path)\n",
    "\n",
    "def collect_random(env, dataset, num_samples=200):\n",
    "    state = env.reset()\n",
    "    for _ in range(num_samples):\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, termi, _ = env.step(action)\n",
    "        dataset.add(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if terminals or timeout:\n",
    "            state = env.reset()\n",
    "\n",
    "def loss(diff, expectile=0.8):\n",
    "    weight = torch.where(diff > 0, expectile, (1 - expectile))\n",
    "    return weight * (diff**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68bff338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:08.714483Z",
     "iopub.status.busy": "2024-08-15T17:36:08.713733Z",
     "iopub.status.idle": "2024-08-15T17:36:08.716465Z",
     "shell.execute_reply": "2024-08-15T17:36:08.715800Z",
     "shell.execute_reply.started": "2024-08-15T16:18:53.610913Z"
    },
    "papermill": {
     "duration": 0.160778,
     "end_time": "2024-08-15T17:36:08.716606",
     "exception": false,
     "start_time": "2024-08-15T17:36:08.555828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(env, policy, eval_runs=5): \n",
    "    \"\"\"\n",
    "    evaluates the current policy\n",
    "    \"\"\"\n",
    "    reward_batch = []\n",
    "    for i in range(eval_runs):\n",
    "        state = env.reset()\n",
    "\n",
    "        rewards = 0\n",
    "        while True:\n",
    "            action = policy.get_action(state, eval=True)\n",
    "\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            rewards += reward\n",
    "            if done:\n",
    "                break\n",
    "        reward_batch.append(rewards)\n",
    "    return np.mean(reward_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df8ae108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:09.033272Z",
     "iopub.status.busy": "2024-08-15T17:36:09.032577Z",
     "iopub.status.idle": "2024-08-15T17:36:19.497708Z",
     "shell.execute_reply": "2024-08-15T17:36:19.496990Z",
     "shell.execute_reply.started": "2024-08-15T16:17:25.060879Z"
    },
    "papermill": {
     "duration": 10.628093,
     "end_time": "2024-08-15T17:36:19.497859",
     "exception": false,
     "start_time": "2024-08-15T17:36:08.869766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.0\r\n",
      "  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\r\n",
      "     |████████████████████████████████| 1.0 MB 7.7 MB/s            \r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 4.24.4\r\n",
      "    Uninstalling protobuf-4.24.4:\r\n",
      "      Successfully uninstalled protobuf-4.24.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\r\n",
      "cudf 21.10.1 requires cupy-cuda110, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.4 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "tfx-bsl 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "tfx-bsl 1.4.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.0 which is incompatible.\r\n",
      "tensorflow 2.6.2 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\r\n",
      "tensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "tensorflow 2.6.2 requires wrapt~=1.12.1, but you have wrapt 1.13.3 which is incompatible.\r\n",
      "tensorflow-transform 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "tensorflow-transform 1.4.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "gcsfs 2021.11.0 requires fsspec==2021.11.0, but you have fsspec 2021.11.1 which is incompatible.\r\n",
      "apache-beam 2.34.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\r\n",
      "apache-beam 2.34.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\r\n",
      "apache-beam 2.34.0 requires pyarrow<6.0.0,>=0.15.1, but you have pyarrow 6.0.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed protobuf-3.20.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0298dadf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:19.817990Z",
     "iopub.status.busy": "2024-08-15T17:36:19.808830Z",
     "iopub.status.idle": "2024-08-15T17:36:28.672278Z",
     "shell.execute_reply": "2024-08-15T17:36:28.671732Z",
     "shell.execute_reply.started": "2024-08-15T16:17:04.516470Z"
    },
    "papermill": {
     "duration": 9.022448,
     "end_time": "2024-08-15T17:36:28.672446",
     "exception": false,
     "start_time": "2024-08-15T17:36:19.649998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.7)\r\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.1.0)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.8)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.5.0)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.0.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.0)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.24)\r\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\r\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.0)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\r\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.1.0)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.8.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\r\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.6.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa2483f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:28.983131Z",
     "iopub.status.busy": "2024-08-15T17:36:28.982290Z",
     "iopub.status.idle": "2024-08-15T17:36:29.778932Z",
     "shell.execute_reply": "2024-08-15T17:36:29.779524Z",
     "shell.execute_reply.started": "2024-08-15T16:17:58.961184Z"
    },
    "papermill": {
     "duration": 0.95477,
     "end_time": "2024-08-15T17:36:29.779709",
     "exception": false,
     "start_time": "2024-08-15T17:36:28.824939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key= \"512e30c6b6b9ff00a20d3fec64a6cab8320827df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd452d2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T17:36:30.144363Z",
     "iopub.status.busy": "2024-08-15T17:36:30.143454Z",
     "iopub.status.idle": "2024-08-15T20:29:37.321980Z",
     "shell.execute_reply": "2024-08-15T20:29:37.322530Z",
     "shell.execute_reply.started": "2024-08-15T16:19:00.017383Z"
    },
    "papermill": {
     "duration": 10387.365893,
     "end_time": "2024-08-15T20:29:37.322795",
     "exception": false,
     "start_time": "2024-08-15T17:36:29.956902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manwar96ibrahim-student\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/anwar96ibrahim-student/offline-RL/runs/2wf3ahi7\" target=\"_blank\">northern-morning-33</a></strong> to <a href=\"https://wandb.ai/anwar96ibrahim-student/offline-RL\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 | Reward: 141.27689229601634 | Polciy Loss: 0.05945054814219475 | Batches: 8334\n",
      "Episode: 2 | Reward: 565.0603867901862 | Polciy Loss: -0.3768186867237091 | Batches: 16668\n",
      "Episode: 3 | Reward: 377.83794733432103 | Polciy Loss: -0.06062809005379677 | Batches: 25002\n",
      "Episode: 4 | Reward: 638.1192285664531 | Polciy Loss: 0.016893576830625534 | Batches: 33336\n",
      "Episode: 5 | Reward: 447.5695230217957 | Polciy Loss: 0.2609432637691498 | Batches: 41670\n",
      "Episode: 6 | Reward: 673.096600330251 | Polciy Loss: -0.13118886947631836 | Batches: 50004\n",
      "Episode: 7 | Reward: 620.6401397553785 | Polciy Loss: -0.03263960778713226 | Batches: 58338\n",
      "Episode: 8 | Reward: 709.1668639396719 | Polciy Loss: -0.3026217222213745 | Batches: 66672\n",
      "Episode: 9 | Reward: 517.0638542285787 | Polciy Loss: -0.2841232717037201 | Batches: 75006\n",
      "Episode: 10 | Reward: 492.7317594395264 | Polciy Loss: -0.3650800585746765 | Batches: 83340\n",
      "Episode: 11 | Reward: 657.4908154424824 | Polciy Loss: 0.20465019345283508 | Batches: 91674\n",
      "Episode: 12 | Reward: 672.4333464350073 | Polciy Loss: -0.21491341292858124 | Batches: 100008\n",
      "Episode: 13 | Reward: 1068.1648969754042 | Polciy Loss: -2.0948140621185303 | Batches: 108342\n",
      "Episode: 14 | Reward: 1052.9734417536042 | Polciy Loss: -0.6703413724899292 | Batches: 116676\n",
      "Episode: 15 | Reward: 839.9233342746398 | Polciy Loss: -1.1108049154281616 | Batches: 125010\n",
      "Episode: 16 | Reward: 944.1838622102529 | Polciy Loss: -0.44498753547668457 | Batches: 133344\n",
      "Episode: 17 | Reward: 840.959904837158 | Polciy Loss: 1.8274738788604736 | Batches: 141678\n",
      "Episode: 18 | Reward: 757.7662836199491 | Polciy Loss: -7.2371931076049805 | Batches: 150012\n",
      "Episode: 19 | Reward: 917.7564573772545 | Polciy Loss: -1.4634623527526855 | Batches: 158346\n",
      "Episode: 20 | Reward: 812.3870887420109 | Polciy Loss: -0.5820156335830688 | Batches: 166680\n",
      "Episode: 21 | Reward: 500.7978717718653 | Polciy Loss: -12.118698120117188 | Batches: 175014\n",
      "Episode: 22 | Reward: 842.3152853122689 | Polciy Loss: -4.8034162521362305 | Batches: 183348\n",
      "Episode: 23 | Reward: 1093.363046955482 | Polciy Loss: -10.937223434448242 | Batches: 191682\n",
      "Episode: 24 | Reward: 933.4351457582176 | Polciy Loss: 12.39159107208252 | Batches: 200016\n",
      "Episode: 25 | Reward: 902.1582095252352 | Polciy Loss: -11.42374324798584 | Batches: 208350\n",
      "Episode: 26 | Reward: 1066.1814369643362 | Polciy Loss: -26.2087459564209 | Batches: 216684\n",
      "Episode: 27 | Reward: 677.5008948219975 | Polciy Loss: -9.03289794921875 | Batches: 225018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 28 | Reward: 904.0057900033789 | Polciy Loss: -8.960646629333496 | Batches: 233352\n",
      "Episode: 29 | Reward: 664.3755467128457 | Polciy Loss: -9.717408180236816 | Batches: 241686\n",
      "Episode: 30 | Reward: 726.3569684411452 | Polciy Loss: -6.751460075378418 | Batches: 250020\n",
      "Episode: 31 | Reward: 1278.9282907839151 | Polciy Loss: -18.18770408630371 | Batches: 258354\n",
      "Episode: 32 | Reward: 1580.5028878455805 | Polciy Loss: -27.257518768310547 | Batches: 266688\n",
      "Episode: 33 | Reward: 678.9210379355616 | Polciy Loss: -7.290257453918457 | Batches: 275022\n",
      "Episode: 34 | Reward: 754.9863360473314 | Polciy Loss: -33.72507095336914 | Batches: 283356\n",
      "Episode: 35 | Reward: 724.195932915189 | Polciy Loss: -15.988669395446777 | Batches: 291690\n",
      "Episode: 36 | Reward: 668.3835380250152 | Polciy Loss: -7.195610046386719 | Batches: 300024\n",
      "Episode: 37 | Reward: 612.6091776175556 | Polciy Loss: -10.702445983886719 | Batches: 308358\n",
      "Episode: 38 | Reward: 837.1028072995923 | Polciy Loss: -16.96207618713379 | Batches: 316692\n",
      "Episode: 39 | Reward: 2897.2917178115854 | Polciy Loss: -11.3678560256958 | Batches: 325026\n",
      "Episode: 40 | Reward: 531.0101421207551 | Polciy Loss: -21.29165267944336 | Batches: 333360\n",
      "Episode: 41 | Reward: 841.1060580702735 | Polciy Loss: -20.501712799072266 | Batches: 341694\n",
      "Episode: 42 | Reward: 836.5823803524299 | Polciy Loss: -26.289541244506836 | Batches: 350028\n",
      "Episode: 43 | Reward: 767.7042672255909 | Polciy Loss: 11.799152374267578 | Batches: 358362\n",
      "Episode: 44 | Reward: 1038.1396635483675 | Polciy Loss: -18.872360229492188 | Batches: 366696\n",
      "Episode: 45 | Reward: 2292.0607704967524 | Polciy Loss: -17.27376937866211 | Batches: 375030\n",
      "Episode: 46 | Reward: 808.7121703758569 | Polciy Loss: -36.04701232910156 | Batches: 383364\n",
      "Episode: 47 | Reward: 722.2376921755236 | Polciy Loss: -29.400007247924805 | Batches: 391698\n",
      "Episode: 48 | Reward: 600.5159384117076 | Polciy Loss: -41.80384063720703 | Batches: 400032\n",
      "Episode: 49 | Reward: 1526.0534475092813 | Polciy Loss: -5.07390022277832 | Batches: 408366\n",
      "Episode: 50 | Reward: 694.5778773123781 | Polciy Loss: -18.60768699645996 | Batches: 416700\n",
      "Episode: 51 | Reward: 707.3205378097771 | Polciy Loss: -6.76694393157959 | Batches: 425034\n",
      "Episode: 52 | Reward: 784.890309213611 | Polciy Loss: -17.4868221282959 | Batches: 433368\n",
      "Episode: 53 | Reward: 670.3124008305972 | Polciy Loss: -12.122915267944336 | Batches: 441702\n",
      "Episode: 54 | Reward: 2884.948227499159 | Polciy Loss: -13.810346603393555 | Batches: 450036\n",
      "Episode: 55 | Reward: 816.8196459144707 | Polciy Loss: -3.591309070587158 | Batches: 458370\n",
      "Episode: 56 | Reward: 768.7323677556444 | Polciy Loss: -7.8234357833862305 | Batches: 466704\n",
      "Episode: 57 | Reward: 714.4707773530754 | Polciy Loss: -27.80531883239746 | Batches: 475038\n",
      "Episode: 58 | Reward: 1012.1291165053274 | Polciy Loss: -9.005751609802246 | Batches: 483372\n",
      "Episode: 59 | Reward: 433.21453863916497 | Polciy Loss: -32.80996322631836 | Batches: 491706\n",
      "Episode: 60 | Reward: 1515.3772677846823 | Polciy Loss: -7.281626224517822 | Batches: 500040\n",
      "Episode: 61 | Reward: 764.2562965986983 | Polciy Loss: -14.23088550567627 | Batches: 508374\n",
      "Episode: 62 | Reward: 781.196929152102 | Polciy Loss: -26.316057205200195 | Batches: 516708\n",
      "Episode: 63 | Reward: 869.6362888131887 | Polciy Loss: -38.915809631347656 | Batches: 525042\n",
      "Episode: 64 | Reward: 1132.5482429445838 | Polciy Loss: -20.12847328186035 | Batches: 533376\n",
      "Episode: 65 | Reward: 2311.7523390577426 | Polciy Loss: -14.372919082641602 | Batches: 541710\n",
      "Episode: 66 | Reward: 852.0111213526527 | Polciy Loss: -30.906801223754883 | Batches: 550044\n",
      "Episode: 67 | Reward: 732.5463311121644 | Polciy Loss: -25.149307250976562 | Batches: 558378\n",
      "Episode: 68 | Reward: 772.2991266777213 | Polciy Loss: -19.38184928894043 | Batches: 566712\n",
      "Episode: 69 | Reward: 766.3068068382653 | Polciy Loss: 2.7908570766448975 | Batches: 575046\n",
      "Episode: 70 | Reward: 965.5091398941553 | Polciy Loss: -22.09925079345703 | Batches: 583380\n",
      "Episode: 71 | Reward: 915.2221341203128 | Polciy Loss: -23.26648712158203 | Batches: 591714\n",
      "Episode: 72 | Reward: 829.1562943445564 | Polciy Loss: -2.694711208343506 | Batches: 600048\n",
      "Episode: 73 | Reward: 809.0160251457013 | Polciy Loss: -7.213482856750488 | Batches: 608382\n",
      "Episode: 74 | Reward: 812.2306409027366 | Polciy Loss: -11.086587905883789 | Batches: 616716\n",
      "Episode: 75 | Reward: 671.9365737331412 | Polciy Loss: -6.2960686683654785 | Batches: 625050\n",
      "Episode: 76 | Reward: 671.3836378421968 | Polciy Loss: -22.154491424560547 | Batches: 633384\n",
      "Episode: 77 | Reward: 744.2760685496693 | Polciy Loss: -18.400415420532227 | Batches: 641718\n",
      "Episode: 78 | Reward: 840.6690306663711 | Polciy Loss: -15.59706974029541 | Batches: 650052\n",
      "Episode: 79 | Reward: 686.5801605420324 | Polciy Loss: -2.2589657306671143 | Batches: 658386\n",
      "Episode: 80 | Reward: 998.1417022657531 | Polciy Loss: -28.6209774017334 | Batches: 666720\n",
      "Episode: 81 | Reward: 654.1206807126671 | Polciy Loss: -10.844053268432617 | Batches: 675054\n",
      "Episode: 82 | Reward: 753.4994655933193 | Polciy Loss: -33.52739334106445 | Batches: 683388\n",
      "Episode: 83 | Reward: 377.38972001599075 | Polciy Loss: -19.90227699279785 | Batches: 691722\n",
      "Episode: 84 | Reward: 1259.5820903564525 | Polciy Loss: -21.464799880981445 | Batches: 700056\n",
      "Episode: 85 | Reward: 1184.633986058517 | Polciy Loss: -25.485166549682617 | Batches: 708390\n",
      "Episode: 86 | Reward: 894.6534308358205 | Polciy Loss: -26.023540496826172 | Batches: 716724\n",
      "Episode: 87 | Reward: 692.1600810109791 | Polciy Loss: -13.82436752319336 | Batches: 725058\n",
      "Episode: 88 | Reward: 991.9350755497089 | Polciy Loss: -25.08778953552246 | Batches: 733392\n",
      "Episode: 89 | Reward: 875.0211909193167 | Polciy Loss: -6.773248672485352 | Batches: 741726\n",
      "Episode: 90 | Reward: 855.8519153296724 | Polciy Loss: -23.752695083618164 | Batches: 750060\n",
      "Episode: 91 | Reward: 940.7483057169845 | Polciy Loss: -28.915740966796875 | Batches: 758394\n",
      "Episode: 92 | Reward: 1007.3574017955722 | Polciy Loss: -13.978081703186035 | Batches: 766728\n",
      "Episode: 93 | Reward: 964.950075995285 | Polciy Loss: -9.040437698364258 | Batches: 775062\n",
      "Episode: 94 | Reward: 1228.8073188988972 | Polciy Loss: -16.077669143676758 | Batches: 783396\n",
      "Episode: 95 | Reward: 813.6161587471609 | Polciy Loss: -17.85622787475586 | Batches: 791730\n",
      "Episode: 96 | Reward: 358.0573815880255 | Polciy Loss: -25.832094192504883 | Batches: 800064\n",
      "Episode: 97 | Reward: 835.4797609364543 | Polciy Loss: -7.719178199768066 | Batches: 808398\n",
      "Episode: 98 | Reward: 830.4892879982814 | Polciy Loss: -28.740520477294922 | Batches: 816732\n",
      "Episode: 99 | Reward: 818.5662357738031 | Polciy Loss: -21.58417320251465 | Batches: 825066\n",
      "Episode: 100 | Reward: 895.3244562748594 | Polciy Loss: -0.9551305770874023 | Batches: 833400\n"
     ]
    }
   ],
   "source": [
    "# Start a W&B Run with wandb.init\n",
    "run = wandb.init(project=\"offline-RL\", config={\"architecture\": \"IQL\",\"dataset\": \"hopper-expert-v2\"})\n",
    "if run:\n",
    "    agent = Implicit_Q_learning(state_size=env.observation_space.shape[0],\n",
    "            action_size=env.action_space.shape[0],\n",
    "            lr=learning_rate,\n",
    "            hidden_size=hidden_size,\n",
    "            tau=tau,\n",
    "            temperature=temperature,\n",
    "            expectile=expectile,\n",
    "            device=device)\n",
    "    run.watch(agent, log=\"gradients\", log_freq=10)\n",
    "    eval_reward = evaluate(env, agent)\n",
    "    run.log({\"Test Reward\": eval_reward, \"Episode\": 0, \"Batches\": batches}, step=batches)\n",
    "    for i in range(1, episodes+1):\n",
    "        for batch_idx, experience in enumerate(dataloader):\n",
    "            states, actions, rewards, next_states, dones = experience\n",
    "            states = states.to(device)\n",
    "            actions = actions.to(device)\n",
    "            rewards = rewards.to(device)\n",
    "            next_states = next_states.to(device)\n",
    "            dones = dones.to(device)\n",
    "            policy_loss, critic1_loss, critic2_loss, value_loss = agent.learn((states, actions, rewards, next_states, dones))\n",
    "            batches += 1\n",
    "            \n",
    "        if i % eval_every == 0:\n",
    "            eval_reward = evaluate(env, agent)\n",
    "            run.log({\"Test Reward\": eval_reward, \"Episode\": i, \"Batches\": batches}, step=batches)\n",
    "\n",
    "            average10.append(eval_reward)\n",
    "            print(\"Episode: {} | Reward: {} | Polciy Loss: {} | Batches: {}\".format(i, eval_reward, policy_loss, batches))\n",
    "            \n",
    "        run.log({\n",
    "            \"Average10\": np.mean(average10),\n",
    "            \"Policy Loss\": policy_loss,\n",
    "            \"Value Loss\": value_loss,\n",
    "            \"Critic 1 Loss\": critic1_loss,\n",
    "            \"Critic 2 Loss\": critic2_loss,\n",
    "            \"Batches\": batches,\n",
    "            \"Episode\": i})\n",
    "        if i % save_every == 0:\n",
    "            save(save_name=\"IQL\", model=agent.actor_local, wandb=run, ep=i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d54f71",
   "metadata": {
    "papermill": {
     "duration": 0.190892,
     "end_time": "2024-08-15T20:29:37.704915",
     "exception": false,
     "start_time": "2024-08-15T20:29:37.514023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Virtual Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10dd144f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T20:29:38.092448Z",
     "iopub.status.busy": "2024-08-15T20:29:38.091775Z",
     "iopub.status.idle": "2024-08-15T20:30:02.299699Z",
     "shell.execute_reply": "2024-08-15T20:30:02.298680Z",
     "shell.execute_reply.started": "2024-08-15T16:06:01.717535Z"
    },
    "papermill": {
     "duration": 24.405846,
     "end_time": "2024-08-15T20:30:02.299870",
     "exception": false,
     "start_time": "2024-08-15T20:29:37.894024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvirtualdisplay\r\n",
      "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: pyvirtualdisplay\r\n",
      "Successfully installed pyvirtualdisplay-3.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!apt install -y python-opengl ffmpeg > /dev/null 2>&1\n",
    "\n",
    "# !apt install -y xvfb\n",
    "%pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fff672dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T20:30:02.743626Z",
     "iopub.status.busy": "2024-08-15T20:30:02.721791Z",
     "iopub.status.idle": "2024-08-15T20:30:11.901345Z",
     "shell.execute_reply": "2024-08-15T20:30:11.901954Z",
     "shell.execute_reply.started": "2024-08-15T16:01:50.884182Z"
    },
    "papermill": {
     "duration": 9.394001,
     "end_time": "2024-08-15T20:30:11.902148",
     "exception": false,
     "start_time": "2024-08-15T20:30:02.508147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.7/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from imageio) (1.19.5)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imageio) (8.2.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2850e4",
   "metadata": {
    "papermill": {
     "duration": 0.190635,
     "end_time": "2024-08-15T20:30:12.285157",
     "exception": false,
     "start_time": "2024-08-15T20:30:12.094522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then import it and define some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b58fd8c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T20:30:12.688295Z",
     "iopub.status.busy": "2024-08-15T20:30:12.682874Z",
     "iopub.status.idle": "2024-08-15T20:30:13.125322Z",
     "shell.execute_reply": "2024-08-15T20:30:13.124746Z",
     "shell.execute_reply.started": "2024-08-15T16:06:30.396783Z"
    },
    "papermill": {
     "duration": 0.646618,
     "end_time": "2024-08-15T20:30:13.125508",
     "exception": false,
     "start_time": "2024-08-15T20:30:12.478890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt, animation\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "def create_anim(frames, dpi, fps):\n",
    "    plt.figure(figsize=(frames[0].shape[1] / dpi, frames[0].shape[0] / dpi), dpi=dpi)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    def setup():\n",
    "        plt.axis('off')\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, init_func=setup, frames=len(frames), interval=fps)\n",
    "    return anim\n",
    "\n",
    "def display_anim(frames, dpi=10, fps=100):\n",
    "    anim = create_anim(frames, dpi, fps)\n",
    "    return anim.to_jshtml()\n",
    "\n",
    "def save_anim(frames, filename, dpi=60, fps=50):\n",
    "    anim = create_anim(frames, dpi, fps)\n",
    "    anim.save(filename)\n",
    "\n",
    "\n",
    "class trigger:\n",
    "    def __init__(self):\n",
    "        self._trigger = True\n",
    "\n",
    "    def __call__(self, e):\n",
    "        return self._trigger\n",
    "\n",
    "    def set(self, t):\n",
    "        self._trigger = t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d435fe",
   "metadata": {
    "papermill": {
     "duration": 0.204455,
     "end_time": "2024-08-15T20:30:13.540101",
     "exception": false,
     "start_time": "2024-08-15T20:30:13.335646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Display Episode Frames In the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95e400",
   "metadata": {
    "papermill": {
     "duration": 0.189581,
     "end_time": "2024-08-15T20:30:13.921596",
     "exception": false,
     "start_time": "2024-08-15T20:30:13.732015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally render an episode and display it in the notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cee8c5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T20:30:14.446938Z",
     "iopub.status.busy": "2024-08-15T20:30:14.325186Z",
     "iopub.status.idle": "2024-08-15T20:31:43.312918Z",
     "shell.execute_reply": "2024-08-15T20:31:43.313473Z"
    },
    "papermill": {
     "duration": 89.198984,
     "end_time": "2024-08-15T20:31:43.313661",
     "exception": false,
     "start_time": "2024-08-15T20:30:14.114677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Reward: 3608.019141577519\n",
      "GIF saved at /kaggle/working/hopper_episode.gif\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "frames = []\n",
    "#env = gym.make(\"Walker2d-v2\")\n",
    "env = gym.make('hopper-expert-v2') \n",
    "obs = env.reset()\n",
    "done = False\n",
    "episode_reward = 0\n",
    "while not done:\n",
    "    frames.append(env.render(mode='rgb_array'))\n",
    "    obs, rew,done,info = env.step(agent.get_action(obs, eval=True))\n",
    "    episode_reward += rew\n",
    "env.close()\n",
    "\n",
    "print(\"Episode Reward: \" + str(episode_reward))\n",
    "\n",
    "#display.HTML(display_anim(frames))\n",
    "# Save frames as a GIF\n",
    "gif_path = \"/kaggle/working/hopper_episode.gif\"\n",
    "imageio.mimsave(gif_path, frames, fps=30)\n",
    "\n",
    "print(f\"GIF saved at {gif_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30152,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10745.662846,
   "end_time": "2024-08-15T20:31:46.339727",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-15T17:32:40.676881",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "11c1ecb79701425288189533264575a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "17a5309bf51b498984d0ff5a989d689b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28596ebc205947699ff7dd1ca6da62e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f05dd7fa73b499b87aca821fdbdc1f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_855a107c93d94e32983b14b2abebbe3f",
        "IPY_MODEL_bccc08e2a5f4416ca8ebb87ef9a9f242"
       ],
       "layout": "IPY_MODEL_28596ebc205947699ff7dd1ca6da62e1"
      }
     },
     "6cb7691ff2c949b39194ac7c60f87383": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "855a107c93d94e32983b14b2abebbe3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_11c1ecb79701425288189533264575a0",
       "placeholder": "​",
       "style": "IPY_MODEL_d01ca02aa35c45c1b2828e1c75e4647d",
       "value": ""
      }
     },
     "bccc08e2a5f4416ca8ebb87ef9a9f242": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_17a5309bf51b498984d0ff5a989d689b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6cb7691ff2c949b39194ac7c60f87383",
       "value": 0.0
      }
     },
     "d01ca02aa35c45c1b2828e1c75e4647d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
